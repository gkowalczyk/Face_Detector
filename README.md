# ğŸ§  Face Analysis App

A futuristic full-stack application that analyzes facial features using **Azure Face API** and **Face++**.  
Built with a **React frontend**, **Spring Boot backend**, and a **MongoDB Atlas** database.

ğŸŒ **Live demo:** [https://face-detector-app.netlify.app/](https://face-detector-app.netlify.app/)

---

## ğŸ“¸ Features

- Submit a photo URL and analyze facial attributes
- Extracted features include:
  - âœ… Age, gender, smile
  - âœ… Glasses, facial hair, makeup
  - âœ… Hair color, baldness, visibility
  - âœ… Blur, exposure, noise, recognition quality
- Live canvas preview with facial bounding box
- Filter faces by attributes using a dynamic form
- Full-stack architecture:
  - **Frontend:** React
  - **Backend:** Spring Boot
  - **APIs:** Azure Face API + Face++
  - **Database:** MongoDB Atlas

---

## ğŸ§ª Practical Use Cases

- ğŸ” **Person Search & Forensics**  
  Identify unknown or wanted individuals by analyzing facial traits and matching them to a stored database.

- ğŸ¥ **Video Scene Analysis**  
  Upload videos, extract frames based on face detection timestamps, and analyze facial features.

- ğŸ§ª **Psychological or Marketing Research**  
  Examine expressions to assess engagement, happiness, or fatigue.

- ğŸ›‚ **Access Control & Identity Validation**  
  Analyze detailed features to support identity verification in secure environments.

---

## ğŸ“ˆ Performance Test Result (Gatling)

**`/api/face/filter`**
- 50 parallel requests
- 100% success
- Avg: 503 ms
- Max: 767 ms  
  ğŸ‘‰ [View report](src/test/java/simulations/index_filter.html)

**`/api/face`**
- 50 parallel requests
- 100% success
- Avg: ~1300â€“1400 ms
- Max: 2946 ms  
  ğŸ‘‰ [View report](src/test/java/simulations/index_analyzeByUrl.html)

---

## ğŸ§© System Architecture & Workflow

### ğŸ”¹ General Overview

- Purpose: Analyze, compare, filter and store face data. Detect faces in images and videos using external APIs.
- Technologies: React, Spring Boot, MongoDB Atlas, Azure Face API, Face++, FFmpeg

### ğŸ”¹ API Documentation

- Swagger UI: [View here](https://facedetector-production-71e7.up.railway.app/webjars/swagger-ui/index.html)

---

## ğŸ§¬ Data Mapping (Java DTOs)

### Class: `FaceObject`

| JSON Key       | Field         | Type           | Description                                 |
|----------------|---------------|----------------|---------------------------------------------|
| face_token     | faceToken     | String         | Unique face ID                              |
| url            | url           | String         | Source image URL                            |
| faceRectangle  | faceRectangle | FaceRectangle  | Bounding box of the detected face           |
| faceLandmarks  | faceLandmarks | FaceLandmarks  | Key facial landmarks (eyes, nose, mouth...) |
| faceAttributes | faceAttributes| FaceAttributes | Attributes extracted from the face          |

### Class: `FaceAttributes`

Includes fields such as:
- `smile`, `age`, `gender`
- `facialHair`, `glasses`, `makeup`
- `blur`, `exposure`, `noise`
- `occlusion`, `hair`, `emotion`, `beauty`, `skinStatus`

Nested objects:
- `HeadPose`, `FacialHair`, `Blur`, `Exposure`, `Noise`, `Hair`, `Emotion`, `Makeup`, `Occlusion`, `SkinStatus`, `Beauty`

---

## ğŸ” Filtering Faces

- The endpoint `/api/face/filter` accepts a `FaceAttributeRequestDto` object
- Server compares attributes to stored data
- Returns a reactive `Flux<FaceObject>` stream that matches the filtering criteria

---

## ğŸ§  Face Matching by Image

- The method `getSimilarFaces(ImgUrl)` queries the Face++ API
- Similar face tokens are retrieved
- The service matches these tokens with database entries and returns a `Flux<FaceObject>`

---

## ğŸ¥ Face Detection from Video

1. Video is uploaded to Azure using `uploadVideo(...)` via `AzureVideoIndexClient`
2. After Azure completes indexing, `analyzeVideo(...)` is called
3. Timestamps for detected faces are returned
4. `VideoFrameExtractor` uses FFmpeg to extract image frames based on timestamps
5. Extracted images are analyzed and saved as `FaceObject` entries

---

## ğŸï¸ Demo Recordings

- ğŸ¥ [Face Analysis](https://github.com/gkowalczyk/Face_Detector/blob/main/src/main/resources/analiza_twarzy.mp4)
- ğŸ¥ [Filtering Faces](https://github.com/gkowalczyk/Face_Detector/blob/main/src/main/resources/filtrowanie_twarzy.mp4)
- ğŸ¥ [Video Analysis](https://github.com/gkowalczyk/Face_Detector/blob/main/src/main/resources/analiza%20z%20video.mp4)
- ğŸ¥ [Identity Verification](https://github.com/gkowalczyk/Face_Detector/blob/main/src/main/resources/weryfikacja_to%C5%BCsamosci.mp4)

---

## ğŸ§© Design Patterns Used

- **Adapter Pattern** â€“ combines and normalizes results from Azure and Face++ APIs
- **Builder Pattern** â€“ for constructing filtering requests 
- **Reactive Programming** â€“ uses `Mono` and `Flux` (Spring WebFlux)

---

## ğŸš€ Future Improvements & Commercial Potential

Planned and potential enhancements include:

- ğŸ“Š **PDF Reporting**  
  Export analysis results and match reports as downloadable PDF files for archival and audit purposes.

- ğŸ” **User Authentication & Roles**  
  Implement login and registration with role-based access (e.g., admin vs. investigator).

- ğŸï¸ **Video & Face Review Interface**  
  Add a dedicated layout to browse uploaded videos, review extracted frames, and inspect detected faces.

- ğŸ§‘â€ğŸ’¼ **Missing Persons Database**  
  Build and manage a structured database of wanted or missing individuals for identity verification.

- ğŸ“ **Custom Metadata Input**  
  Allow users to input personal details (e.g., name, ID, case number) to associate with analyzed faces.

- ğŸ“‚ **Face Analysis History & Audit Trail**  
  Maintain a searchable history of past analyses, including timestamps and user activity logs.

- ğŸ“¶ **Live RTSP Stream Support**  
  Analyze faces in real time from security camera feeds or public IP cameras.

- ğŸŒ **Multilingual Interface**  
  Add language switching (e.g., English/Polish) for international or public safety use cases.

- ğŸ“¡ **WebSocket Notifications**  
  Use WebSockets to notify frontend in real time when video analysis is complete or faces are detected.

- ğŸ§  **LLM Integration (e.g., GPT)**  
  Summarize emotional profiles, suggest matches, or provide context-aware insights using AI models.

- ğŸ§ª **Batch Upload & Analysis Mode**  
  Support uploading and processing multiple images or videos in one session.

- ğŸ“Š **Dashboard Analytics**  
  Provide admin users with statistical summaries (e.g., most common age range, smile level trends).

- ğŸ”’ **Secure API Key Access**  
  Add authentication tokens for controlled access to public endpoints.

- ğŸ“ **Integration with External Databases (e.g., Interpol)**  
  Match detected faces against global datasets via standardized APIs.