import React, {useState} from "react";
import FaceResult from "./components/FaceResult";
import FaceAppForm from "./components/FaceAppForm";
import FaceImagePreview from "./components/FaceImagePreview";
import SideBarMenu from "./components/SideBarMenu";
import FaceFilterForm from "./components/FaceFilterForm";
import VideoUploadForm from "./components/VideoUploadForm";
import "./App.css"

function App() {
    const [faceData, setFaceData] = useState(null);
    const [imageUrl, setImageUrl] = useState('');
    const [view, setView] = useState("analyze");
    const [filterData, setFilterData] = useState([]);
    const [matchedData, setMatchedData] = useState([]);
    const [videoFaces, setVideoFaces] = useState([]);
    const [isAnalyzing, setIsAnalyzing] = useState(false);

    const handleImageSubmit = async (url) => {
        try {
            setImageUrl(url)
           // const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face", {
              //  const response = await fetch("http://localhost:8081/api/face", {
            const response = await fetch("https://face-detector-app.site/api/face", {

                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({url})
            });
            const data = await response.json();
            setFaceData(data);

        } catch (error) {
            console.error("B≈ÇƒÖd pobierania danych:", error);
        }
    }
    const handleFilterSubmit = async (filterData) => {


        try {
            //const response = await fetch("http://localhost:8081/api/face/filter", {
           // const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face/filter", {
                const response = await fetch("https://face-detector-app.site/api/face/filter", {

                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify(filterData)

            });
            console.log("Wysy≈Çane dane filtracji:", filterData);
            const data = await response.json();
            console.log("Odebrane dane z backendu:", data);
            setFilterData(data);

        } catch (error) {
            console.error("B≈ÇƒÖd pobierania danych:", error);
        }
    };

    const handleMachSubmit = async (url) => {
        try {
            setImageUrl(url);
            // const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face/getSimilar", {
           // const response = await fetch("http://localhost:8081/api/face/getSimilar", {
                 const response = await fetch("https://face-detector-app.site/api/face/getSimilar", {

                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({url})
            });
            const data = await response.json();
            setMatchedData(data);
        } catch(error) {
            console.error("B≈ÇƒÖd pobierania danych:", error);
        }
    }

    const startVideoAnalysis = (videoId) => {
        setIsAnalyzing(true);

        const poll = setInterval(async () => {
            try {
                //const response = await fetch(`http://localhost:8081/api/video/callback?id=${videoId}&state=Processed`, {
                 // const response = await fetch(`https://facedetector-production-71e7.up.railway.app/api/video/callback?id=${videoId}&state=Processed`, {
                      const response = await fetch(`https://face-detector-app.site/api/video/callback?id=${videoId}&state=Processed`, {

                    method: "POST"
                });
                const data = await response.json();
                const isDifferent = JSON.stringify(data) !== JSON.stringify(videoFaces);
                if(data.length > 0 && isDifferent) {
                    clearInterval(poll);
                    setIsAnalyzing(false);
                    setVideoFaces(data);
                }
            } catch (error) {
                console.error("Polling error:", error);
            }
        }, 10000);
    };



    return (

        <div className="app-with-sidebar" style={{display: "flex"}}>
            <div className="sidebar-container">
                <SideBarMenu onMenuItemClick={setView}/>
                {view === "filter" && <FaceFilterForm onFilter={handleFilterSubmit}/>}
            </div>

            <div className="app-container">
                <h1 className="title">RAPORT ANALIZY TWARZY</h1>

                {view === "analyze" && (
                    <>
                        <FaceAppForm onSubmit={handleImageSubmit}/>
                        <div className="content-wrapper">
                            <FaceImagePreview imageUrl={imageUrl} faceData={faceData}/>
                            <FaceResult faceData={faceData} view={view} />
                        </div>
                    </>
                )}

                {view === "filter" && (
                    <>
                        {filterData.length === 0 ? (
                            <div className="hud-panel">
                                <p style={{ color: "white", textAlign: "center" }}>Brak wynik√≥w pasujƒÖcych do filtr√≥w.</p>
                            </div>
                        ) : (
                            filterData.map((face, index) => (
                                <div key={index} className="content-wrapper">
                                    <FaceImagePreview imageUrl={face.url} faceData={face}/>
                                    <FaceResult faceData={face} view={view} />
                                </div>
                            ))
                        )}
                    </>
                )}

                {view === "verify" && (
                    <>
                        <FaceAppForm onSubmit={handleMachSubmit}/>
                        {matchedData.length === 0 ? (
                            <div className="hud-panel">
                                <p style={{ color: "white", textAlign: "center" }}>Brak wynik√≥w z dopasowaniem.
                                Interfejs zwraca 3 najbardziej dopasowane twarze.</p>
                            </div>
                        ) : (
                            matchedData.map((face, index) => (
                                <div key={index} className="content-wrapper">
                                    <FaceImagePreview imageUrl={face.url} faceData={face}/>
                                    <FaceResult faceData={face} view={view} />
                                </div>
                            ))
                        )}
                    </>
                )}

                {view === "analyze-video" && (
                 <>
                 <VideoUploadForm onStart={startVideoAnalysis}/>
                 {isAnalyzing && <p style={{ color: "white" }}>‚åõ Trwa analiza wideo...</p>}
                 {videoFaces.map((face, index) => (
                        <div key={index} className="content-wrapper">
                            <FaceImagePreview imageUrl={face.url} faceData={face}/>
                            <FaceResult faceData={face} view={"analyze"} />
                        </div>
                 ))}
                 </>
                )}


                {view === "about" && (
                    <div className="hud-panel">
                        <h2>O AUTORZE</h2>
                        <p><strong>Autor:</strong> Grzegorz Kowalczyk</p>

                        <h4>üõ† Technologie</h4>
                        <ul>
                            <li>Frontend: React.js</li>
                            <li>Backend: Spring Boot WebFlux + MongoDB</li>
                            <li>AI: Azure Face API + Face++</li>
                        </ul>

                        <h4>üéØ Funkcjonalno≈õci aplikacji</h4>
                        <ul>
                            <li>Analiza twarzy z obraz√≥w URL</li>
                            <li>Wizualizacja cech: wiek, emocje, zarost, okulary, makija≈º</li>
                            <li>Filtrowanie twarzy z bazy danych</li>
                            <li>Weryfikacja to≈ºsamo≈õci ‚Äì por√≥wnywanie twarzy</li>
                            <li>Analiza wideo z URL ‚Äì rozpoznawanie twarzy w filmach</li>
                            <li>Zapis dopasowa≈Ñ do bazy danych (MongoDB)</li>
                        </ul>

                        <h4>üìº Analiza wideo z URL</h4>
                        <p>
                            Aplikacja obs≈Çuguje analizƒô twarzy w przes≈Çanych filmach poprzez integracjƒô z us≈ÇugƒÖ  Azure AI Video Indexer.
                            Wideo mo≈ºe zostaƒá przes≈Çane przez bezpo≈õredni link (np. do pliku .mp4), a po
                            zako≈Ñczeniu indeksowania aplikacja pobiera fragmenty zawierajƒÖce wykryte twarze.
                        </p>

                        <h4>‚öôÔ∏è Wymagania techniczne dla analizy wideo</h4>
                        <ul>
                            <li><strong>Maksymalny rozmiar wideo z URL:</strong> 30 GB</li>
                            <li><strong>Maksymalna d≈Çugo≈õƒá filmu:</strong> 6 godzin</li>
                            <li><strong>Minimalna d≈Çugo≈õƒá filmu:</strong> powy≈ºej 2 sekund</li>
                            <li><strong>Obs≈Çugiwane formaty:</strong> MP4, AVI, MOV, MKV, WMV, FLV, TS, itp.</li>
                            <li><strong>Obs≈Çugiwane kodeki wideo:</strong> H.264 (AVC), MPEG-2, HEVC (H.265), WMV9, Theora, itp.</li>
                            <li><strong>Obs≈Çugiwane kodeki audio:</strong> AAC, MP3, FLAC, WAV, WMA, itp.</li>
                            <li><strong>Limit OCR:</strong> do 50 000 s≈Ç√≥w na wideo</li>
                        </ul>

                        <p>
                            Podczas przesy≈Çania plik√≥w nale≈ºy upewniƒá siƒô, ≈ºe link wskazuje bezpo≈õrednio na plik wideo, a nie na stronƒô typu YouTube.
                        </p>

                        <h4>üí° Oparte na technologii Azure AI Face</h4>
                        <p>
                            Aplikacja wykorzystuje Azure AI Face Service, kt√≥ra dostarcza algorytmy do wykrywania, rozpoznawania i analizowania ludzkich twarzy w obrazach.
                        </p>
                        <ul>
                            <li> Weryfikacja to≈ºsamo≈õci u≈ºytkownika (one-to-one)</li>
                            <li> Identyfikacja twarzy w grupie (one-to-many)</li>
                            <li> Kontrola dostƒôpu bezdotykowego</li>
                            <li> Analiza emocji i atrybut√≥w (wiek, zarost, uczesanie itd.)</li>
                            <li> Detekcja liveness (czy osoba jest fizycznie obecna)</li>
                        </ul>
npm
                                               <p><strong>Repozytorium projektu:</strong> <br />
                                                   <a href="https://github.com/..." target="_blank" rel="noreferrer">
                                https://github.com/gkowalczyk/Face_Detector
                            </a></p>
                        <h4>üì∏ Wymagania dotyczƒÖce zdjƒôƒá</h4>
                        <p>W celu skutecznej analizy twarzy, przesy≈Çane zdjƒôcia muszƒÖ spe≈Çniaƒá poni≈ºsze wymagania techniczne i jako≈õciowe:</p>

                        <ul>
                            <li><strong>Format pliku:</strong> JPEG, PNG, BMP, WEBP (brak wsparcia dla TIFF, HEIC)</li>
                            <li><strong>Maksymalny rozmiar pliku:</strong> 6 MB</li>
                            <li><strong>Zalecany rozmiar twarzy:</strong> co najmniej 200x200 pikseli</li>
                            <li><strong>Twarz powinna zajmowaƒá min. 50% zdjƒôcia i byƒá wy≈õrodkowana</strong></li>
                            <li><strong>O≈õwietlenie:</strong> zdjƒôcie dobrze do≈õwietlone, bez cieni i bez efektu czerwonych oczu</li>
                            <li><strong>Pozycja:</strong> twarz zwr√≥cona na wprost, oczy otwarte, usta zamkniƒôte, brak przechylenia g≈Çowy</li>
                            <li><strong>Jedna twarz na zdjƒôciu</strong> ‚Äì aplikacja analizuje tylko jednƒÖ osobƒô</li>
                        </ul>

                        <h4>üö´ Unikaƒá:</h4>
                        <ul>
                            <li>Okular√≥w przeciws≈Çonecznych, maseczek, czapek, s≈Çuchawek zakrywajƒÖcych twarz</li>
                            <li>Zdjƒôƒá z niskƒÖ jako≈õciƒÖ (rozmycie, szum, s≈Çaba rozdzielczo≈õƒá)</li>
                            <li>T≈Ça z du≈ºym kontrastem lub z elementami rozpraszajƒÖcymi</li>
                                                    </ul>
                    </div>
                )}
            </div>

        </div>
    );
}

export default App;