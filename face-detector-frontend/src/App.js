import React, {useState} from "react";
import FaceResult from "./components/FaceResult";
import FaceAppForm from "./components/FaceAppForm";
import FaceImagePreview from "./components/FaceImagePreview";
import SideBarMenu from "./components/SideBarMenu";
import FaceFilterForm from "./components/FaceFilterForm";

import "./App.css"

function App() {
    const [faceData, setFaceData] = useState(null);
    const [imageUrl, setImageUrl] = useState('');
    const [view, setView] = useState("analyze");
    const [filterData, setFilterData] = useState([]);
    const [matchedData, setMatchedData] = useState([]);

    const handleImageSubmit = async (url) => {
        try {
            setImageUrl(url)
            const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face", {
              //  const response = await fetch("http://localhost:8081/api/face", {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({url})
            });
            const data = await response.json();
            setFaceData(data);

        } catch (error) {
            console.error("BÅ‚Ä…d pobierania danych:", error);
        }
    }
    const handleFilterSubmit = async (filterData) => {


        try {
            //const response = await fetch("http://localhost:8081/api/face/filter", {
            const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face/filter", {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify(filterData)

            });
            console.log("WysyÅ‚ane dane filtracji:", filterData);
            const data = await response.json();
            console.log("Odebrane dane z backendu:", data);
            setFilterData(data);

        } catch (error) {
            console.error("BÅ‚Ä…d pobierania danych:", error);
        }
    };

    const handleMachSubmit = async (url) => {
        try {
            setImageUrl(url);
             const response = await fetch("https://facedetector-production-71e7.up.railway.app/api/face/getSimilar", {
           // const response = await fetch("http://localhost:8081/api/face/getSimilar", {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({url})
            });
            const data = await response.json();
            setMatchedData(data);
        } catch(error) {
            console.error("BÅ‚Ä…d pobierania danych:", error);
        }
    }


    return (
        <div className="app-with-sidebar" style={{display: "flex"}}>
            <div className="sidebar-container">
                <SideBarMenu onMenuItemClick={setView}/>
                {view === "filter" && <FaceFilterForm onFilter={handleFilterSubmit}/>}
            </div>

            <div className="app-container">
                <h1 className="title">RAPORT ANALIZY TWARZY</h1>

                {view === "analyze" && (
                    <>
                        <FaceAppForm onSubmit={handleImageSubmit}/>
                        <div className="content-wrapper">
                            <FaceImagePreview imageUrl={imageUrl} faceData={faceData}/>
                            <FaceResult faceData={faceData} view={view} />
                        </div>
                    </>
                )}

                {view === "filter" && (
                    <>
                        {filterData.length === 0 ? (
                            <div className="hud-panel">
                                <p style={{ color: "white", textAlign: "center" }}>Brak wynikÃ³w pasujÄ…cych do filtrÃ³w.</p>
                            </div>
                        ) : (
                            filterData.map((face, index) => (
                                <div key={index} className="content-wrapper">
                                    <FaceImagePreview imageUrl={face.url} faceData={face}/>
                                    <FaceResult faceData={face} view={view} />
                                </div>
                            ))
                        )}
                    </>
                )}

                {view === "verify" && (
                    <>
                        <FaceAppForm onSubmit={handleMachSubmit}/>
                        {matchedData.length === 0 ? (
                            <div className="hud-panel">
                                <p style={{ color: "white", textAlign: "center" }}>Brak wynikÃ³w z dopasowaniem.
                                Interfejs zwraca 3 najbardziej dopasowane twarze.</p>
                            </div>
                        ) : (
                            matchedData.map((face, index) => (
                                <div key={index} className="content-wrapper">
                                    <FaceImagePreview imageUrl={face.url} faceData={face}/>
                                    <FaceResult faceData={face} view={view} />
                                </div>
                            ))
                        )}
                    </>
                )}

                {view === "about" && (
                    <div className="hud-panel">
                        <h2>O AUTORZE</h2>
                        <p><strong>Autor:</strong> Grzegorz Kowalczyk</p>

                        <h4>ðŸ›  Technologie</h4>
                        <ul>
                            <li>Frontend: React.js</li>
                            <li>Backend: Spring Boot WebFlux + MongoDB</li>
                            <li>AI: Azure Face API + Face++</li>
                        </ul>

                        <h4>ðŸŽ¯ FunkcjonalnoÅ›ci aplikacji</h4>
                        <ul>
                            <li>Analiza twarzy z obrazÃ³w URL</li>
                            <li>Wizualizacja cech: wiek, emocje, zarost, okulary, makijaÅ¼</li>
                            <li>Filtrowanie twarzy z bazy danych</li>
                            <li>Weryfikacja toÅ¼samoÅ›ci â€“ porÃ³wnywanie twarzy</li>
                            <li>Zapis dopasowaÅ„ do bazy danych (MongoDB)</li>
                        </ul>

                        <h4>ðŸ’¡ Oparte na technologii Azure AI Face</h4>
                        <p>
                            Aplikacja wykorzystuje Azure AI Face Service, ktÃ³ra to dostarcza algorytmy do wykrywania, rozpoznawania i analizowania ludzkich twarzy w obrazach. PrzykÅ‚adowe scenariusze uÅ¼ycia to:
                        </p>
                        <ul>
                            <li> Weryfikacja toÅ¼samoÅ›ci uÅ¼ytkownika (one-to-one)</li>
                            <li> Identyfikacja twarzy w grupie (one-to-many)</li>
                            <li> Kontrola dostÄ™pu bezdotykowego</li>
                            <li> Analiza emocji i atrybutÃ³w (wiek, zarost, uczesanie itd.)</li>
                            <li> Detekcja liveness (czy osoba jest fizycznie obecna)</li>
                        </ul>

                                               <p><strong>Repozytorium projektu:</strong> <br />
                                                   <a href="https://github.com/..." target="_blank" rel="noreferrer">
                                https://github.com/gkowalczyk/Face_Detector
                            </a></p>
                        <h4>ðŸ“¸ Wymagania dotyczÄ…ce zdjÄ™Ä‡</h4>
                        <p>W celu skutecznej analizy twarzy, przesyÅ‚ane zdjÄ™cia muszÄ… speÅ‚niaÄ‡ poniÅ¼sze wymagania techniczne i jakoÅ›ciowe:</p>

                        <ul>
                            <li><strong>Format pliku:</strong> JPEG, PNG, BMP, WEBP (brak wsparcia dla TIFF, HEIC)</li>
                            <li><strong>Maksymalny rozmiar pliku:</strong> 6 MB</li>
                            <li><strong>Zalecany rozmiar twarzy:</strong> co najmniej 200x200 pikseli</li>
                            <li><strong>Twarz powinna zajmowaÄ‡ min. 50% zdjÄ™cia i byÄ‡ wyÅ›rodkowana</strong></li>
                            <li><strong>OÅ›wietlenie:</strong> zdjÄ™cie dobrze doÅ›wietlone, bez cieni i bez efektu czerwonych oczu</li>
                            <li><strong>Pozycja:</strong> twarz zwrÃ³cona na wprost, oczy otwarte, usta zamkniÄ™te, brak przechylenia gÅ‚owy</li>
                            <li><strong>Jedna twarz na zdjÄ™ciu</strong> â€“ aplikacja analizuje tylko jednÄ… osobÄ™</li>
                        </ul>

                        <h4>ðŸš« UnikaÄ‡:</h4>
                        <ul>
                            <li>OkularÃ³w przeciwsÅ‚onecznych, maseczek, czapek, sÅ‚uchawek zakrywajÄ…cych twarz</li>
                            <li>ZdjÄ™Ä‡ z niskÄ… jakoÅ›ciÄ… (rozmycie, szum, sÅ‚aba rozdzielczoÅ›Ä‡)</li>
                            <li>TÅ‚a z duÅ¼ym kontrastem lub z elementami rozpraszajÄ…cymi</li>
                                                    </ul>
                    </div>
                )}
            </div>
        </div>
    );
}

export default App;